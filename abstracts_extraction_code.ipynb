{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19347d60-c6de-4630-99c2-9b35efc701cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaecce3-6527-42f4-b4d9-610695cc8df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstracts_paginated(total=100, start_year=2018, end_year=2025):\n",
    "    \"\"\"Get abstracts using pagination with robust error handling\"\"\"\n",
    "    base_url = \"https://api.openalex.org/works\"\n",
    "    headers = {\n",
    "        'User-Agent': 'AcademicResearchBot/1.0',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "    \n",
    "    filters = [\n",
    "        \"type:article\",\n",
    "        f\"publication_year:>{start_year-1}\",\n",
    "        f\"publication_year:<{end_year+1}\",\n",
    "        \"has_abstract:true\"\n",
    "    ]\n",
    "    \n",
    "    abstracts = []\n",
    "    page = 1\n",
    "    per_page = 25\n",
    "    \n",
    "    print(f\"Starting to collect {total} abstracts...\")\n",
    "    \n",
    "    while len(abstracts) < total:\n",
    "        params = {\n",
    "            'filter': ','.join(filters),\n",
    "            'select': 'id,title,abstract_inverted_index,publication_year,authorships,primary_location,doi',\n",
    "            'per-page': per_page,\n",
    "            'page': page\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(f\"Fetching page {page}...\")\n",
    "            response = requests.get(base_url, params=params, headers=headers, timeout=30)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                print(\"Rate limited. Waiting 10 seconds...\")\n",
    "                time.sleep(10)\n",
    "                continue\n",
    "                \n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if not data.get('results'):\n",
    "                print(\"No more results available\")\n",
    "                break\n",
    "                \n",
    "            for work in data['results']:\n",
    "                if len(abstracts) >= total:\n",
    "                    break\n",
    "                    \n",
    "                # Skip if work is None or missing critical data\n",
    "                if not work:\n",
    "                    continue\n",
    "                    \n",
    "                # Process abstract \n",
    "                abstract_text = \"\"\n",
    "                try:\n",
    "                    if work.get('abstract_inverted_index'):\n",
    "                        inverted_index = work['abstract_inverted_index']\n",
    "                        if isinstance(inverted_index, dict):\n",
    "                            word_positions = []\n",
    "                            for word, positions in inverted_index.items():\n",
    "                                if isinstance(positions, list):\n",
    "                                    for pos in positions:\n",
    "                                        word_positions.append((pos, word))\n",
    "                            word_positions.sort()\n",
    "                            abstract_text = ' '.join([word for pos, word in word_positions])\n",
    "                    \n",
    "                    # Only include if abstract is meaningful \n",
    "                    if abstract_text and len(abstract_text.strip()) > 50:  \n",
    "                        abstract_info = {\n",
    "                            'id': work.get('id', ''),\n",
    "                            'title': work.get('title', ''),\n",
    "                            'abstract': abstract_text,\n",
    "                            'year': work.get('publication_year'),\n",
    "                            'doi': work.get('doi', ''),\n",
    "                            'authors_count': len(work.get('authorships', [])),\n",
    "                            'source': work.get('primary_location', {}).get('source', {}).get('display_name', '') if work.get('primary_location') else ''\n",
    "                        }\n",
    "                        abstracts.append(abstract_info)\n",
    "                        print(f\"Collected {len(abstracts)}/{total} abstracts\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing work: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            page += 1\n",
    "            time.sleep(1)  \n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error on page {page}: {e}\")\n",
    "            break\n",
    "    \n",
    "    return abstracts\n",
    "\n",
    "def save_abstracts_to_csv(abstracts, filename='abstracts_sample.csv'):\n",
    "    if abstracts:\n",
    "        df = pd.DataFrame(abstracts)\n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        print(f\"Saved {len(abstracts)} abstracts to {filename}\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting abstract extraction using paginated approach...\")\n",
    "    \n",
    "    abstracts = get_abstracts_paginated(total=100, start_year=2018, end_year=2025)\n",
    "    \n",
    "    if abstracts:\n",
    "        save_abstracts_to_csv(abstracts)\n",
    "        print(f\"\\nSuccess! Collected {len(abstracts)} abstracts\")\n",
    "        if abstracts:\n",
    "            print(f\"Sample title: {abstracts[0]['title'][:50]}...\")\n",
    "            print(f\"Abstract preview: {abstracts[0]['abstract'][:100]}...\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve abstracts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
